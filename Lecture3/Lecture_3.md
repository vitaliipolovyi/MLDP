---
marp: true
title: ML&DP Lecture 3
theme: default
size: 16:9
class: header-slide
style: |
  section {
    position: relative;
    text-align: justify;
    padding-top: 0px;
    padding-bottom: 0px
  }
  h1 {
    text-align: left;
  }
  img[alt~="top-right"] {
    position: absolute;
    top: 20px;
    right: 20px;
    width: 150px;
  }
  img[alt~="centered-img"] {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 100%; 
  }
  h1:not(.section-header) {
    position: absolute;
    top: 30px;
    left: 70px;
    right: 0;
    text-align: left;
    margin: 0;
    /* font-size: 2em; */
  }
  .centered-text {
    text-align: center
  }
footer: '**Національний університет "Львівська політехніка" | Кафедра прикладної математики**'
---

<!-- paginate: skip -->

<h1 class="section-header">Лекція 3</h1>

## Типи даних, збір та інтеграція


![top-right](../am_logo.png)

---

# Вступ

<!-- paginate: true -->

Якість і точність аналітики значною мірою залежать від того, з якими даними ми працюємо. Перед тим як аналізувати або моделювати дані, необхідно розуміти, які бувають типи даних, як їх правильно збирати та інтегрувати з різних джерел.

Різні типи даних — числові, категоріальні, текстові чи часові — мають свої особливості обробки, зберігання та аналізу. Помилки на цьому етапі можуть призвести до хибних висновків, некоректних моделей і стратегічних рішень, що не відповідають реальності.

![top-right](../am_logo.png)

---


<h1 class="section-header">Теорія інформації Шеннона</h1>

![top-right](../am_logo.png)

---

# Теорія інформації Шеннона

Збирання та інтеграція даних має інформаційний аспект: важливо розуміти, наскільки нові дані зменшують невизначеність щодо системи чи явища. Основні концепції теорії інформації дозволяють кількісно оцінити, чи є дані корисними, чи вони лише дублюють уже відоме або створюють додатковий шум.

![top-right](../am_logo.png)

---

# Ентропія

Ентропія випадкової величини $X$ з розподілом ймовірностей $p(x)$ визначається так:
$$
H(X) = - \sum_{x \in \mathbb{X}} p(x) \log p(x)
$$
Ентропія є мірою невизначеності або “середнього обсягу інформації”, яку ми отримуємо при спостереженні $X$.

![top-right](../am_logo.png)

---

# Ентропія

- Якщо всі події однаково ймовірні (наприклад, підкидання справедливої монети або кубика), ентропія максимальна, бо результат неможливо передбачити наперед. 
- Якщо ж якась подія майже гарантована (наприклад, монета завжди падає орлом), то ентропія близька до нуля, адже результат практично відомий.

![top-right](../am_logo.png)

---

# Підкидання "справедливої" монети

Тут $p(\text{орел})=0.5$, $p(\text{решка})=0.5$. Тоді:
$$
H = - (0.5 \log_2 0.5 + 0.5 \log_2 0.5) = 1 \text{ біт}.
$$
Це означає, що кожне підкидання несе рівно 1 біт інформації.  
А якщо монета "неправильна", наприклад $p(\text{орел})=0.9$, $p(\text{решка})=0.1$, то:
$$
H \approx 0.47 \text{ біт},
$$
що відображає знижену невизначеність.

![top-right](../am_logo.png)

---

# Кидання "справедливого" кубика

Тут позначимо $X \in {1,2,3,4,5,6}$, а $p(x)=1/6$ для кожного значення. Тоді:
$$
H(X) = -6 \cdot \tfrac{1}{6}\log_2 \tfrac{1}{6} = \log_2 6 \approx 2.585 \text{ біта}.
$$

Це означає, що щоб визначити результат кидка кубика, в середньому потрібно близько 2.6 бінарних запитань.

Практично це можна уявити так:
- одне запитання відсікає половину можливостей,
- друге — знову ділить решту,
- третє остаточно уточнює.  

Усього максимум 3 запитання.

![top-right](../am_logo.png)

---

# Одинці вимірювання ентропії

Одиниця вимірювання ентропії залежить від основи логарифма у формулі:
- якщо береться $\log_2$, то ентропія вимірюється в *бітах*;
- якщо використати натуральний логарифм $\ln$, то отримаємо ентропію в *натах* (від "natural units");
- якщо $\log_{10}$ — тоді в *децибанах*.

![top-right](../am_logo.png)

---

# Одинці вимірювання ентропії

Практично це можна уявити так:
- одне запитання відсікає половину можливостей,
- друге — знову ділить решту,
- третє остаточно уточнює.  
Усього максимум 3 запитання, але в середньому потрібно приблизно 2.6.

У класичній теорії інформації Шеннона стандартом є *біти*, бо це напряму пов’язано з кількістю бінарних запитань “так/ні”, які потрібно поставити, щоб визначити значення випадкової величини.

![top-right](../am_logo.png)

---

# Умовна ентропія

Умовна ентропія $H(Y|X)$ показує, скільки невизначеності залишається щодо $Y$, якщо значення $X$ вже відоме:
$$
⁡p(y∣x).H(Y|X) = - \sum_{x \in \mathbb{X}} \sum_{y \in \mathbb{Y}} p(x,y) \log p(y|x).
$$
- Якщо $X$ повністю визначає $Y$, то $H(Y|X)=0$.
- Якщо ж $X$ не містить жодної інформації про $Y$, то $H(Y|X)=H(Y)$.

![top-right](../am_logo.png)

---

# Студент іспит — підготовка

Нехай $Y =$ “чи складе студент іспит” (${\text{склав}, \text{провалив}}$), $X =$ “чи готувався студент” (${\text{так}, \text{ні}}$).
Припустимо, ми знаємо такі ймовірності:
- $P(X=\text{так}) = 0.6$, $P(X=\text{ні}) = 0.4$.
- Якщо студент готувався:
  - $P(Y=\text{склав}|X=\text{так})=0.9$,
  - $P(Y=\text{провалив}|X=\text{так})=0.1$.
- Якщо не готувався:
  - $P(Y=\text{склав}|X=\text{ні})=0.3$, 
  - $P(Y=\text{провалив}|X=\text{ні})=0.7$.

![top-right](../am_logo.png)

---

# Ентропія результату без знання $X$

Обчислюємо загальні ймовірності:
- $P(Y=\text{склав}) = 0.6\cdot 0.9 + 0.4\cdot 0.3 = 0.54 + 0.12 = 0.66$.
- $P(Y=\text{провалив}) = 1 - 0.66 = 0.34$.
Тоді:
$$
H(Y) = -0.66\log_2 0.66 - 0.34\log_2 0.34 \approx 0.93 \text{ біта}.
$$

![top-right](../am_logo.png)

---

# Умовна ентропія

### невизначеність щодо $Y$, якщо відомо $X$:

Якщо $X=\text{так}$:
$$
H(Y|X=\text{так}) = -0.9\log_2 0.9 - 0.1\log_2 0.1 \approx 0.47 \text{ біта}.
$$
Якщо $X=\text{ні}$:
$$
H(Y|X=\text{ні}) = -0.3\log_2 0.3 - 0.7\log_2 0.7 \approx 0.88 \text{ біта}.
$$

Зважуємо за ймовірностями $P(X)$:
$$
H(Y|X) = 0.6 \cdot 0.47 + 0.4 \cdot 0.88 \approx 0.63 \text{ біта}.
$$

![top-right](../am_logo.png)

---

# Умовна ентропія

**Висновок:**
- Без знання $X$ невизначеність щодо результату іспиту $H(Y)=0.93$ біта.
- Якщо ми знаємо, чи студент готувався, невизначеність падає до $H(Y|X)=0.63$ біта.
- Тобто знання $X$ зменшує нашу невизначеність — воно дійсно корисне.

![top-right](../am_logo.png)

---

# Взаємна інформація

Взаємна інформація між $X$ і $Y$ вимірює, наскільки знання одного зменшує невизначеність щодо іншого:
$$
I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X).
$$
Іншими словами, $I(X;Y)$ показує, скільки інформації про $X$ міститься в $Y$ і навпаки.

У машинному навчанні взаємна інформація часто використовується для відбору ознак: якщо якась ознака має високу взаємну інформацію з цільовою змінною, вона є корисною для передбачення; якщо низьку — можливо, її варто відкинути.

![top-right](../am_logo.png)

---

# Приклад

У задачі класифікації текстів (наприклад, спам/не спам) ознака “наявність слова _free_” має високу взаємну інформацію з класом “спам”, а ознака “кількість голосних у тексті” має низьку взаємну інформацію, оскільки практично не впливає на результат.

![top-right](../am_logo.png)

---

# Інтеграція даних

Пи об’єднанні кількох джерел даних можна використати концепції ентропії та взаємної інформації, щоб оцінити їхню цінність.
- Якщо додавання нового джерела зменшує ентропію цільової змінної (наприклад, результату прогнозу чи класифікації), то воно вносить нову інформацію.
- Якщо ж взаємна інформація між новим джерелом та вже наявними даними дуже висока, то воно може бути надлишковим, адже містить ту саму інформацію.
- Якщо ж взаємна інформація низька не лише з цільовою змінною, але й з іншими джерелами, тоді джерело є майже “шумовим” і не покращує точність.

![top-right](../am_logo.png)

---

# Конкретний приклад

У медичних дослідженнях для прогнозу хвороби використовують набір показників (аналізи крові, дані МРТ, історію хвороби). Якщо додати ще один показник — наприклад, рівень певного білка, — то можна виміряти, наскільки він зменшує невизначеність діагнозу. Якщо ентропія прогнозу значно зменшується, показник інформативний. Якщо ж нова змінна сильно корелює з уже наявними (наприклад, із рівнем іншого білка), її внесок буде мінімальним.

![top-right](../am_logo.png)

---

<h1 class="section-header">Визначення даних</h1>

![top-right](../am_logo.png)

---

# Вступ / формалізація

Нехай у проєкті є множина спостережень (об’єктів) $\mathbb{D} = \{(x_i, y_i)\}_{i=1}^n$, де $x_i \in \mathbb{X}$ — вектор ознак розмірності $d$, а $y_i$ — ціль/мітка (може бути відсутнім для задач без нагляду).

Вибір і представлення $\mathbb{X}$ та якість $\mathbb{D}$ визначають практичну можливість успішного навчання функції $f:\mathbb{X}\to\mathbb{Y}$. Тому ключові етапи — коректне означення типів ознак, збір (sampling) та інтеграція джерел даних — мають строгі математичні формулювання та критерії якості.

![top-right](../am_logo.png)

---

# Типи даних

### формальні визначення та наслідки для обробки

Кожну ознаку $j$ формально можна трактувати як відображення з множини об’єктів у множину значень: $x^{(j)}: \mathbb{D} \to \mathbb{V}_j$. Типи $\mathbb{V}_j$ часто бувають:
- числові: $\mathbb{V}_j \subseteq \mathbb{R}$ (неперервні) або $\mathbb{V}_j \subseteq \mathbb{Z}$ (дискретні);
- порядкові: скінченна впорядкована множина $\{v_1 \prec v_2 \prec \dots\}$;
- номінальні: скінченна множина без порядку;
- текстові: послідовності токенів $w_1 \dots w_m$;
- зображення: функції на решітці $I: \Omega \subset \mathbb{Z}^2 \to [0,255]^3$;
- часові ряди: функції часу $x(t)$, $t\in \mathbb{T}$;
- графи: $G=(V,E)$ з атрибутами на вершинах/ребрах.

![top-right](../am_logo.png)

---

# Типи даних

- Для числових ознак використовуються відстані й скалярні операції;
- Для категоріальних — перетворення (one-hot, target-encoding); для тексту — векторизація (TF, TF-IDF, embeddings);
- Для часових рядів — ресемплінг та лаг-ознаки; для графів — матриці суміжності/векторні ембеддінги.

---

<h1 class="section-header">Пропущені дані</h1>

![top-right](../am_logo.png)

---

# Пропущені дані

### Ймовірнісна постановка та механізми відсутності

Позначимо матрицю спостережень $X=(x_{ij})$ та маску присутності $M=(m_{ij})$, де $m_{ij}=1$ якщо $x_{ij}$ спостерігається, і $m_{ij}=0$ якщо пропуск.

![top-right](../am_logo.png)

---

# Пропущені дані

Визначають три класичні механізми відсутності:
1. **MCAR (Missing Completely At Random)/** $P(M \mid X, Y) = P(M)$. Пропуски не залежать ні від спостережуваних, ні від не спостережуваних даних.
2. **MAR (Missing At Random).** $P(M \mid X, Y) = P(M \mid X_{obs})$. Пропуски можуть залежати від спостережуваних ознак, але не від самих прихованих значень.
3. **MNAR (Missing Not At Random).** $P(M \mid X, Y)$ залежить від невідкритих значень $X_{mis}$ або $Y$ — найскладніший випадок.

![top-right](../am_logo.png)

---

# Пропущені дані

Метод імпутації має враховувати механізм відсутності.
- при MCAR прості методи можуть бути несхильні до упереджень;
- при MAR рекомендується умовна імпутація;
- при MNAR потрібні моделі явного моделювання механізму відсутності.

![top-right](../am_logo.png)

---

# Методи імпутації

**Імпутація даних** — це процес заповнення відсутніх значень у наборі даних на основі доступної інформації. Вона використовується для того, щоб зберегти повноту даних і забезпечити коректність статистичного аналізу чи навчання моделей машинного навчання, оскільки більшість алгоритмів не можуть працювати з пропусками.

![top-right](../am_logo.png)

---

# Методи імпутації

Основна ідея імпутації полягає в тому, щоб “відновити” відсутні дані, спираючись на:
- статистичні характеристики змінної (наприклад, середнє, медіана, мода),
- залежності між ознаками (наприклад, регресійні моделі, kNN-імпутація),
- складніші методи, як-от багатократна імпутація (MICE) або моделі глибокого навчання.

Таким чином, імпутація дозволяє уникнути втрати інформації, яка виникла б при простому видаленні неповних спостережень, і зменшити спотворення результатів аналізу.

![top-right](../am_logo.png)

---

# Методи імпутації

Нехай для ознаки $j$ існує набір спостережуваних значень $S_j=\{x_{ij}: m_{ij}=1\}.$

### Виділять такі простi методи

**Mean імпутація:** $\hat{x}_{ij} = \bar{x}_j \;=\; \frac{1}{|S_j|}\sum_{k:m_{kj}=1} x_{kj}.$
**Median імпутація:** $\hat{x}_{ij} = \mathrm{median}(S_j).$
**Mode (категоріальні):** $\hat{x}_{ij} = \arg\max_{v}\{k: x_{kj}=v\}.$

Ці методи прості, але зменшують варіативність і можуть знизити кореляції.

![top-right](../am_logo.png)

---

# k-NN імпутація (середнє за сусідами)

Нехай $d(\cdot,\cdot)$ — метрика між повними/частково повними векторами (наприклад, Евклідова по спільних ознаках). Для рядка ii знайдемо $N_k(i)$ — індекси $k$ найменших відстаней серед рядків, що мають значення у $j$-й колонці. Імпутація (зважена) дається як:
$$
\hat{x}_{ij} = \frac{\sum_{m\in N_k(i)} w_{m} x_{mj}}{\sum_{m\in N_k(i)} w_m},\qquad w_m = \frac{1}{d(x_i,x_m)^\alpha + \varepsilon}
$$
з параметром $\alpha\ge 0$ ($\alpha=1$).

![top-right](../am_logo.png)

---

# Імпутація регресією

Побудуємо модель $g_j$ для ознаки $j$ як функцію інших ознак:
$$
x_{ij} \approx g_j(x_{i,-j};\beta).
$$
Імпутація: $\hat{x}_{ij} = g_j(x_{i,-j};\hat\beta)$, де $\hat\beta$ — оцінка на спостережених рядках.

![top-right](../am_logo.png)

---

# Множинна імпутація (MICE)

MICE будує послідовність умовних моделей для кожної змінної з пропусками. Формально на кожній ітерації $t$ для ознаки $j$ ми моделюємо
$$
x^{(j)} = g_j\big( x^{(-j)} ; \theta_j^{(t)} \big) + \varepsilon
$$
і замінюємо пропуски на випадкові заміни з умовного розподілу, повторюючи цикл по всім $j.$ Після $T$ ітерацій отримуємо одну імпутацію; множинна імпутація будується шляхом повторення процесу $L$ разів і агрегування оцінок з урахуванням між- та внутрішньо-імпутаційної варіації (Rubin’s rules).

![top-right](../am_logo.png)

---

# Матрична факторизація


**Матрична факторизація** — це метод, за допомогою якого велику матрицю розкладають на добуток двох (або більше) менших матриць, які відображають приховану (латентну) структуру даних.

Маємо матрицю $X \in \mathbb{R}^{m \times n}$, яка містить пропущені значення.

Ми хочемо знайти дві матриці:
- $P \in \mathbb{R}^{m \times k}$
- $Q \in \mathbb{R}^{n \times k}$

такі, що:
$$
X \approx P Q^T
$$
де $k \ll \min(m, n)$ — кількість **латентних факторів**, тобто прихованих рис.

![top-right](../am_logo.png)

---

# Приклад

Уявімо, що $X$ — це матриця оцінок фільмів, де рядки це користувачі, стовпці — фільми, $X_{ij}$ — оцінка користувача $i$ фільму $j$, деякі оцінки відсутні (користувачі не оцінили деякі фільми)

Матрична факторизація намагається дізнатисяякі характеристики фільму важливі (жанр, драма, комедія, актори…) та кі уподобання має кожен користувач

Іншими словами:
- $P[i]$ — це "вектор уподобань" користувача $i$
- $Q[j]$ — це "вектор характеристик" фільму $j$

Тоді $P[i] \cdot Q[j]^T \approx X_{ij}$ — передбачена оцінка.

![top-right](../am_logo.png)

---

# Алгоритм

1. **Ініціалізація:**
   Випадково ініціалізуємо матриці $P$ і $Q$
2. **Цільова функція:**
   Мінімізуємо помилку лише на *відомих* значеннях:
   $$
   \min_{P, Q} \sum_{(i, j) \in \Omega} \left( X_{ij} - P_i \cdot Q_j^T \right)^2 + \lambda \left( \|P_i\|^2 + \|Q_j\|^2 \right)
   $$

   * $\Omega$ — набір відомих (непропущених) значень
   * $\lambda$ — коефіцієнт регуляризації для запобігання перенавчанню

![top-right](../am_logo.png)

---

# Алгоритм

3. **Ітеративна оптимізація:**

   * Застосовують градієнтний спуск або альтернативну мінімізацію (спочатку фіксуємо $Q$, оновлюємо $P$, потім навпаки)

4. **Передбачення пропущених значень:**

   * Обчислюємо $\hat{X} = P Q^T$
   * Пропущені значення в $X$ заповнюємо з $\hat{X}$

![top-right](../am_logo.png)

---

# Оцінювання якості імпутації

Якщо доступна «істинна» непошкоджена підвибірка, імпутацію можна оцінити за:
$$
\text{RMSE}_{imp} = \sqrt{ \frac{1}{N_{mis}} \sum_{(i,j)\in \mathbb{M}} (x_{ij} - \hat{x}_{ij})^2 }.
$$
Тут $\mathbb{M}$ — множина відновлених елементів.

![top-right](../am_logo.png)

---

<h1 class="section-header">Нормалізація та масштабування</h1>

![top-right](../am_logo.png)

---

# Нормалізація та масштабування

У багатьох алгоритмах (kNN, k-means, SVM з RBF-ядром) основна міра близькості — Евклідова відстань:
$$
d(\mathbf{x}, \mathbf{z}) = \sqrt{\sum_{j=1}^d (x_j - z_j)^2}.
$$
Якщо ознаки мають різний масштаб, то ознака з великою дисперсією $\sigma_j^2$ матиме непропорційно великий внесок. Нормалізація приводить усі ознаки до спільного масштабу, щоб уникнути домінування однієї з них.

![top-right](../am_logo.png)

---

# Z-score стандартизація

Для ознаки $j$ розраховується:
$$
x_{ij}^{(std)} = \frac{x_{ij} - \mu_j}{\sigma_j}, \qquad \mu_j = \frac{1}{n}\sum_{i=1}^n x_{ij},\ \sigma_j^2 = \frac{1}{n}\sum_{i=1}^n (x_{ij}-\mu_j)^2.
$$
### Властивості:
- $\mathbb{E}[x_{ij}^{(std)}] = 0,\quad \mathrm{Var}(x_{ij}^{(std)}) = 1$.
- Всі ознаки отримують однакову дисперсію, що робить їх внесок у відстані рівнозначним.
- Коваріаційна матриця стандартизованих даних збігається з кореляційною матрицею:
$$
\Sigma_{std} = \mathrm{Corr}(X).
$$

![top-right](../am_logo.png)

---

# Min–Max масштабування
$$
x_{ij}^{(mm)} = \frac{x_{ij} - \min_k x_{kj}}{\max_k x_{kj} - \min_k x_{kj}}, \qquad x_{ij}^{(mm)} \in [0,1].
$$
### Властивості:
- Лінійно масштабує ознаки в діапазон $[0,1]$.
- Зберігає відношення відстаней між точками, але чутливий до викидів.
- Добре працює для алгоритмів, де важлива інтерпретація як ймовірностей чи часток.

![top-right](../am_logo.png)

---

# Робастне масштабування

Використовує медіану $m_j$ та інтерквартильний розмах $IQR_j = Q_{3,j} - Q_{1,j}$:
$$
x_{ij}^{(rob)} = \frac{x_{ij} - m_j}{IQR_j}.
$$
### Властивості:
- Менш чутливий до викидів, ніж Z-score.
- Зберігає інваріантність до екстремальних значень.

![top-right](../am_logo.png)

---

# Вплив на градієнтні методи

У задачі оптимізації (наприклад, лінійної регресії)
$$
\min_\beta L(\beta) = \|X\beta - y\|^2,
$$
швидкість збіжності градієнтного спуску залежить від числа обумовленості матриці $X^\top X$:
$$
\kappa(X^\top X) = \frac{\lambda_{\max}(X^\top X)}{\lambda_{\min}(X^\top X)}.
$$
Без нормалізації ознаки з різними масштабами дають погано обумовлену матрицю, що сповільнює збіжність. Масштабування зменшує $\kappa$, тому алгоритм збігається швидше.

![top-right](../am_logo.png)

---

# Вплив на регуляризацію

У задачах із Lasso або Ridge регуляризацією:
$$
\min_\beta \|X\beta - y\|^2 + \lambda \|\beta\|_1 \quad \text{або} \quad \min_\beta \|X\beta - y\|^2 + \lambda \|\beta\|_2^2,
$$
величина $\beta_j$ напряму залежить від масштабу ознаки $x_j$. Якщо одна ознака в 1000 разів більша за іншу, то її коефіцієнт $\beta_j$ стане в 1000 разів меншим, навіть якщо реальний вплив однаковий. Це спотворює інтерпретацію та роботу регуляризації. Нормалізація забезпечує справедливе порівняння важливості ознак.

![top-right](../am_logo.png)

---

# Вплив на PCA

PCA виконує розкладання коваріаційної матриці:
$$
\Sigma = \frac{1}{n} X^\top X.
$$
Якщо ознаки мають різні масштаби, то напрямки головних компонент визначаються переважно ознаками з більшою дисперсією. Стандартизація ZZ-оцінками забезпечує рівний внесок усіх ознак у PCA, інакше аналіз буде упередженим.

![top-right](../am_logo.png)

---

# Кодування категоріальних змінних

**One-hot encoding**. Для номінальної ознаки з $K$ категоріями утворюється вектор розмірності $K$ (або $K-1$ при уникненні мультиколінеарності у лінійних моделях):

якщо $\text{onehot}(x_j) \in \{0,1\}^K$ де компонент $k = 1$, якщо $x_j=v_k$.

![top-right](../am_logo.png)

---

**Target / Mean encoding (з регуляризацією).** При високій кардинальності категорій замість one-hot іноді застосовують таргет-енкодинг. Нехай по категорії $c$ маємо середнє цілі $\bar{y}_c$ і кількість $n_c$. Згладжена оцінка:
$$
\text{TE}(c) = \frac{n_c \bar{y}_c + \alpha \bar{y}_{global}}{n_c + \alpha},
$$
де $\alpha$ — параметр згладжування (псевдо-попередні), $\bar{y}_{global}$ — глобальне середнє. Для бінарної цілі це дає ймовірнісну інтерпретацію з регуляризацією.

**Ordinal encoding.** Якщо порядок має сенс, відобразити категорії у числа $1,\dots,K$ зберігає відношення порядку; слід бути обережним з інтерпретацією цих чисел у моделях.

![top-right](../am_logo.png)

---

# Часові ряди


Нехай маємо ряд $x(t_i),\ i=1,\dots,n$, $t_{i}$ — часи спостережень не обов’язково рівно віддалені.

При роботі з часовими рядами виділяють такі три основні техніки: ресемплінг, інтерполяція, агрегування.


### Ресемплінг на сітку $\{s_k\}$

Мета: отримати $x'(s_k)$ для рівномірної сітки $s_k$.

![top-right](../am_logo.png)

---

# Лінійна інтерполяція та заповнення

**Лінійна інтерполяція**
Якщо $t_i < s_k < t_{i+1}$,
$$
x'(s_k) = x(t_i) + \frac{s_k - t_i}{t_{i+1} - t_i}\big(x(t_{i+1}) - x(t_i)\big).
$$
**Поліноміальна інтерполяція / spline** — більш гладкі методи, але більш схильні до коливань.

**Forward-fill / Backward-fill:** константне тримання останнього/наступного значення.

![top-right](../am_logo.png)

---

# Агрегація та Антиаліасинг

**Агрегація (downsampling)**
Агрегувати на інтервал $[s_k, s_{k+1})$ можна середнім:
$$
x_{agg}(k) = \frac{1}{|\mathbb{I}_k|}\sum_{t_i\in \mathbb{I}_k} x(t_i),
$$
або сумою, максимумом тощо.

**Антиаліасинг (Nyquist)**
Якщо сигнал має частотний компонент $f_{max}$, то щоб уникнути спотворень при дискретизації потрібна частота вибірки $f_s > 2 f_{max}$ (Nyquist). Інакше високочастотні компоненти «згортаються» у нижні частоти (aliasing). При зменшенні частоти (downsampling) рекомендовано застосовувати low-pass фільтр (усереднення), щоб уникнути aliasing.

![top-right](../am_logo.png)

---

<h1 class="section-header">Інтеграція джерел</h1>

![top-right](../am_logo.png)

---

# Інтеграція джерел

Нехай маємо $k$ джерел $D^{(1)},\dots,D^{(k)}$. Кожне джерело містить набір записів з атрибутами і можливими ключами.

![top-right](../am_logo.png)

---

# Реляційний join 

При наявності унікального ідентифікатора $id$ інтегрований запис $z$ утворюється як:
$$
Z = \{ z_i = \bigcup_{r=1}^k D^{(r)}[id=i]\ :\ i\in \mathbb{I}\},
$$
де $\bigcup$ — операція об’єднання атрибутів (з можливими правилами конфліктів).

![top-right](../am_logo.png)

---

# Record linkage / Entity resolution

### Fellegi–Sunte
Коли прямих ключів немає, використовується ймовірнісний підхід. Для пари записів $(p,q)$, де $a\in D^{(p)}$, $b\in D^{(q)}$ обчислюють вагу узгодження як суму ваг по полях:
$$
w(a,b) = \sum_{\ell=1}^L \log\frac{m_\ell(a_\ell,b_\ell)}{u_\ell(a_\ell,b_\ell)},
$$
де $m_{\ell}$ — ймовірність спостереження співпадіння $\ell$-го поля при реальному злитті (match), $u_\ell$ — відповідна ймовірність при невідповідності (non-match). Поріг на $w$ дозволяє віднести пару до match / possible / non-match.

Практично $m_\ell$ та $u_\ell$ оцінюють емпірично. Часто використовують комбіновану оцінку через лог-арифм.

![top-right](../am_logo.png)

---

# Розв’язання конфліктів

Якщо для атрибута $a$ з двох джерел є різні значення $v_1$ та $v_2$, можна застосувати вагове схлопування:
$$
v^* = \arg\max_v \sum_{r: D^{(r)}.a=v} w_r,
$$
де $w_r$ — довіра/якість джерела $r$. Інший підхід — Bayesian fusion: якщо кожне джерело дає ймовірнісну оцінку $p_r(\theta)$ про істинну величину $\theta$, то комбінована апостеріорна щільність:
$$
p(\theta \mid \{D^{(r)}\}) \propto p(\theta) \prod_{r} p_r(D^{(r)} \mid \theta).
$$

![top-right](../am_logo.png)

---

<h1 class="section-header">Якість інтеграції</h1>

![top-right](../am_logo.png)

---

# Повнота (completeness)

Для очікуваної множини унікальних сутностей $|\mathbb{E}_{exp}|$, які ми очікували отримати (наприклад, список усіх клієнтів з CRM) після інтеграції отримано кількість унікальних сутностей, які реально присутні в інтегрованому наборі даних $|\mathbb{E}_{int}|$:
$$
\text{Completeness} = \frac{|\mathbb{E}_{int}|}{|\mathbb{E}_{exp}|}.
$$
  
Показник відображає, наскільки наш набір даних *повний* відносно очікуваної множини. Якщо значення дорівнює 1 — усі очікувані сутності є присутні, якщо < 1 — частина сутностей втрачена, якщо > 1 (теоретично можливо, якщо інтеграція привела до появи сутностей, яких не було в очікуваному списку) — треба перевірити якість джерел та визначення «очікуваного простору».

![top-right](../am_logo.png)

---

# Узгодженість (consistency)

Нехай $\mathbb{C}$ — множина правил цілісності (наприклад, формат телефону, діапазон віку), і $viol(r)$ — кількість порушених правил для запису $r$. Тоді
$$
\text{Consistency} = 1 - \frac{1}{|Z|}\sum_{r\in Z} \frac{viol(r)}{|\mathbb{C}|}.
$$
$Z$ — набір записів (рядків), $\mathbb{C}$ — набір правил цілісності (наприклад, email повинен мати символ “@”, вік — у діапазоні 0–120), $viol(r)$ — кількість порушень для запису $r$.

Таким чином, ми рахуємо середню частку порушених правил на один запис і віднімаємо її від 1. Значення 1 означає, що всі записи повністю узгоджені. Значення 0 означає, що всі можливі правила порушені у кожному записі. Значення між 0 і 1 показує частку даних, які дотримуються правил.

![top-right](../am_logo.png)

---

# Надлишковість (redundancy)

$$
\text{Redundancy} = \frac{|Z| - |\text{unique}(Z)|}{|Z|}.
$$
вимірює частку елементів у множині (або векторі/стовпці даних) які є дубльованими. Тут $|Z|$ — загальна кількість записів (довжина масиву), а $|\operatorname{unique}(Z)|$ — кількість різних (унікальних) значень.
начення лежить у межах $[0,,1)$ (для скінченного $|Z|$). Якщо $\text{Redundancy}=0$, то всі значення унікальні (жодних дублікатів). Якщо $\text{Redundancy}$ близька до 1, — багато дублікатів.

![top-right](../am_logo.png)

---

# Відмінність розподілів

Вкористовуєтьсядля оцінки адекватності джерел.

Коли ми інтегруємо дані з кількох джерел, важливо перевірити, чи мають вони *сумісні розподіли ознак*. Якщо одна й та ж ознака має суттєво різні розподіли у двох джерелах, це може свідчити про:
- різні методи збору або обробки даних;
- систематичні помилки в одному джерелі;
- зміни в часі (data drift).

![top-right](../am_logo.png)

---

# Kullback–Leibler дивергенція

Вкиористовують для порівняння, *наскільки розподіли ознаки* $j$ в джерелах $p$ і $q$ *збігаються* (якщо визначені щільності $p_j$, $q_j$):
$$
D_{KL}(p\|q) = \sum_x p(x)\log\frac{p(x)}{q(x)}.
$$
Вимірює, скільки додаткової «інформації» потрібно для опису розподілу $p$, якщо замість нього використовувати модель $q$.
- Асиметрична: $D_{KL}(p\|q) \neq D_{KL}(q\|p).$
- $D_{KL}(p\|q)=0$, якщо розподіли повністю збігаються.
- Коли цікавить «втрата інформації» при заміні одного джерела іншим.
Якщо дивергенція мала, розподіли досить схожі.

![top-right](../am_logo.png)

---

# Jensen–Shannon дивергенція

Також, виділяють більш симетричну Jensen–Shannon дивергенцію:
$$
D_{JS}(p,q) = \frac{1}{2}D_{KL}(p\|m) + \frac{1}{2}D_{KL}(q\|m),\qquad m=\frac{p+q}{2}.
$$

- Це симетричний і завжди обмежений показник (знаходиться в діапазоні $[0,1]$ при логарифмах за основою 2).
- Зручніший для порівняння розподілів, ніж $D_{KL}$​, бо враховує обидва напрямки.    
- Використовується в задачах *порівняння якості джерел* та *кластеризації розподілів*.

![top-right](../am_logo.png)

---

# Population Stability Index (PSI)

PSI використовується для виявлення *data drift* — тобто, коли розподіл ознаки змінюється з часом.  Зазвичай є *контрольна вибірка (baseline)* і *поточна вибірка (current)*.
Для бінів $b$:
$$
\text{PSI} = \sum_{b} (p_b - q_b)\log\frac{p_b}{q_b},
$$
де $p_b$ — частка у контрольній (baseline) вибірці, $q_b$ — у поточній. Якщо
- $\text{PSI} \approx 0$ - розподіли дуже подібні.
- $0.1 \leq \text{PSI} < 0.25$ - помірний дрейф, варто перевірити.
- $\text{PSI} \geq 0.25$ - суттєвий дрейф, модель може втратити актуальність.

![top-right](../am_logo.png)

---

<h1 class="section-header">Аномалії</div>

![top-right](../am_logo.png)

---

# Аномалії

### Одновимірні правила

Z-score: вважати точку аномальною, якщо
$$
|x - \mu| > k\sigma,\qquad \text{часто } k=3.
$$
Tukey (IQR) rule: поза межами
$$
[x_{Q1} - 1.5\cdot IQR,\ x_{Q3} + 1.5\cdot IQR].
$$

![top-right](../am_logo.png)

---

# Мультівимірні методи

**Відстань Махаланобіса:**
$$
D^2(\mathbf{x}) = (\mathbf{x}-\boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{x}-\boldsymbol{\mu}).
$$
Якщо $\mathbf{x}$ нормальний, то $D^2$ має $\chi^2_d$-розподіл; отже поріг $\chi^2_{d,\;1-\alpha}$ дає критерій для рівня $\alpha$.

LOF (Local Outlier Factor) і інші методи базуються на локальних щільностях; формули детальні у відповідній літературі, але сутність — співвідношення локальної щільності точки та середньої локальної щільності сусідів.

![top-right](../am_logo.png)

---

# Практичні поради

- Вибір методу імпутації. При MAR краще використовувати умовні моделі (регресія, MICE), при MCAR прості методи можуть бути допустимі; при MNAR потрібно моделювати механізм відсутності.
- Scaling перед PCA. PCA чутливий до масштабу ознак, тому робимо стандартизацію $z-score$ перед розрахунком $\Sigma$.
- Record linkage. Використовувати лог-ліквідаційні ваги $w=\sum \log(m_\ell / u_\ell)$; вибір порогів має базуватись на оцінці FPR/TPR для пар.
- Об’єднання різних періодів. Ресемплити до найбільш грубої (низької) частоти з anti-aliasing (усереднення) перед downsampling.

![top-right](../am_logo.png)

---

<h1 class="section-header">Контроль якості після інтеграції</h1>

![top-right](../am_logo.png)

---

# KS-test

Використовується для числових розподілів.
Cтатистика $D = \sup_x |F_1(x)-F_2(x)|$.
Перевіряє, чи два *числових* розподіли є статистично однаковими.
- $F_1(x)$ та $F_2(x)$ — емпіричні функції розподілу (ECDF) двох вибірок.
- $\sup_x$​ — найбільша відмінність між цими функціями по всіх $x$.
 Порівнює форму розподілу (не лише середнє, а й медіану, хвости, тощо). Якщо DD велике — розподіли суттєво різні. Також, дає p-значення, яке показує ймовірність побачити таку різницю, якщо насправді розподіли однакові.
 
![top-right](../am_logo.png)

---

# Chisquare

Використовується для категоріальних даних. Перевіряє, чи дві *категоріальні* змінні мають однаковий розподіл (тобто сумісність). Створюється таблиця частот (наприклад: скільки разів зустрічається кожна категорія до і після інтеграції).
Обчислюється статистика:
$$
 	\chi^2 = \sum{\frac{(O_i - E_i)^2}{E_i}}
$$
де $O_i$​ — спостережене значення, $E_i$​ — очікуване (якщо розподіл не змінився). Якщо різниця між очікуваними і спостереженими значеннями велика — є підозра на зміну розподілу.

![top-right](../am_logo.png)

---

# Permutation test

Використовується для перевірки, чи походять два зразки з "одного джерела". Підходить для *будь-яких типів даних* (числових або категоріальних) і не вимагає сильних припущень про розподіли.
- Об'єднуємо дві вибірки (старі й нові дані).
- Багато разів випадково перемішуємо мітки "старі/нові".
- Для кожного перемішування обчислюємо різницю метрики.
- Дивимося, як часто така різниця траплялася випадково — це і є p-value.

Тест не потребує нормального розподілу, працює навіть на малих вибірках, підходить для перевірки будь-якої метрики (не лише середнього).

![top-right](../am_logo.png)
